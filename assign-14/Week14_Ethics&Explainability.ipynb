{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b3feda5",
   "metadata": {},
   "source": [
    "# **Week 14 – Ethics & Explainability (SHAP)**\n",
    "\n",
    "**Class Task: Explain Model Predictions using SHAP**\n",
    "\n",
    "- Objective\n",
    "\n",
    "To understand why the model predicts a certain house price, not just what it predicts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f9ec7a",
   "metadata": {},
   "source": [
    "Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f310ccec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\naree\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP version: 0.50.0\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"SHAP version:\", shap.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f5ad1e",
   "metadata": {},
   "source": [
    "Step 2: Load Model & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f38ff844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/7] Loading model and data...\n",
      "✓ Data loaded: 1458 samples, 3 features\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[1/7] Loading model and data...\")\n",
    "model = joblib.load(\"house_price_model.pkl\")\n",
    "df = pd.read_csv(\"train_cleaned.csv\")\n",
    "\n",
    "# Select features\n",
    "X = df[['GrLivArea', 'OverallQual', 'GarageCars']]\n",
    "print(f\"✓ Data loaded: {X.shape[0]} samples, {X.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8150f4",
   "metadata": {},
   "source": [
    "Step 3: Use SMALLER sample to prevent crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa4045e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2/7] Preparing sample data...\n",
      "✓ Using 50 samples for SHAP analysis\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[2/7] Preparing sample data...\")\n",
    "X_sample = X.sample(n=50, random_state=42)  # Reduced to 50\n",
    "print(f\"✓ Using {X_sample.shape[0]} samples for SHAP analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc39b82",
   "metadata": {},
   "source": [
    "Step 4: Create SHAP Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b172a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/7] Creating SHAP explainer...\n",
      "✓ Using TreeExplainer\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[3/7] Creating SHAP explainer...\")\n",
    "try:\n",
    "    # Try TreeExplainer first (for RandomForest, XGBoost, etc.)\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    print(\"✓ Using TreeExplainer\")\n",
    "except:\n",
    "    # Fallback to KernelExplainer if TreeExplainer fails\n",
    "    print(\"⚠ TreeExplainer failed, using KernelExplainer...\")\n",
    "    background = shap.sample(X_sample, 10)\n",
    "    explainer = shap.KernelExplainer(model.predict, background)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c2f331",
   "metadata": {},
   "source": [
    "Step 5: Calculate SHAP values (SAFER METHOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "520489f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4/7] Calculating SHAP values...\n",
      "✓ SHAP values calculated successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[4/7] Calculating SHAP values...\")\n",
    "try:\n",
    "    shap_values = explainer.shap_values(X_sample, check_additivity=False)\n",
    "    print(\"✓ SHAP values calculated successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Error: {e}\")\n",
    "    print(\"Trying alternative method...\")\n",
    "    # Alternative: compute one at a time\n",
    "    shap_values = np.array([explainer.shap_values(X_sample.iloc[[i]], check_additivity=False)[0] \n",
    "                            for i in range(len(X_sample))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717164a8",
   "metadata": {},
   "source": [
    "Step 6: Simple Text-Based Feature Importance (NO PLOTTING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "733387a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5/7] Computing feature importance...\n",
      "\n",
      "============================================================\n",
      "FEATURE IMPORTANCE SUMMARY (SHAP Values)\n",
      "============================================================\n",
      "1. GarageCars     : 365493.82 ████████████████████████████████████████\n",
      "2. GrLivArea      : 61990.64 ██████\n",
      "3. OverallQual    : 48162.87 █████\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[5/7] Computing feature importance...\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE IMPORTANCE SUMMARY (SHAP Values)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_sample.columns,\n",
    "    'Mean |SHAP|': mean_abs_shap,\n",
    "    'Rank': range(1, len(X_sample.columns) + 1)\n",
    "}).sort_values('Mean |SHAP|', ascending=False).reset_index(drop=True)\n",
    "\n",
    "feature_importance['Rank'] = range(1, len(feature_importance) + 1)\n",
    "\n",
    "for idx, row in feature_importance.iterrows():\n",
    "    bar = \"█\" * int(row['Mean |SHAP|'] / mean_abs_shap.max() * 40)\n",
    "    print(f\"{row['Rank']}. {row['Feature']:15s}: {row['Mean |SHAP|']:8.2f} {bar}\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950ad590",
   "metadata": {},
   "source": [
    "Step 7: Local Explanation for ONE sample (Text-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5183ca06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[6/7] Local explanation for first sample:\n",
      "------------------------------------------------------------\n",
      "Sample Input:\n",
      "  GrLivArea      : 1923\n",
      "  OverallQual    : 7\n",
      "  GarageCars     : 2\n",
      "\n",
      "SHAP Contributions:\n",
      "  GrLivArea      : +18631.82 ↑\n",
      "  OverallQual    : +27784.55 ↑\n",
      "  GarageCars     : +436135.63 ↑\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to numpy.ndarray.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m     direction = \u001b[33m\"\u001b[39m\u001b[33m↑\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m contribution > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m↓\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m15s\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontribution\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m+8.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirection\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mBase prediction: \u001b[39m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbase_value\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[33;43m.2f\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFinal adjustment: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshap_values[\u001b[32m0\u001b[39m].sum()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m+.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m60\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: unsupported format string passed to numpy.ndarray.__format__"
     ]
    }
   ],
   "source": [
    "print(\"\\n[6/7] Local explanation for first sample:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"Sample Input:\")\n",
    "for col in X_sample.columns:\n",
    "    print(f\"  {col:15s}: {X_sample.iloc[0][col]}\")\n",
    "\n",
    "print(\"\\nSHAP Contributions:\")\n",
    "base_value = explainer.expected_value if hasattr(explainer, 'expected_value') else X['SalePrice'].mean() if 'SalePrice' in df else 0\n",
    "\n",
    "for i, col in enumerate(X_sample.columns):\n",
    "    contribution = shap_values[0][i]\n",
    "    direction = \"↑\" if contribution > 0 else \"↓\"\n",
    "    print(f\"  {col:15s}: {contribution:+8.2f} {direction}\")\n",
    "\n",
    "print(f\"\\nBase prediction: {base_value:.2f}\")\n",
    "print(f\"Final adjustment: {shap_values[0].sum():+.2f}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e1b0d2",
   "metadata": {},
   "source": [
    "Step 8: Save SHAP values to CSV for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21068fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[7/7] Saving results...\n",
      "✓ SHAP values saved to 'shap_values.csv'\n",
      "✓ Sample data saved to 'shap_sample_data.csv'\n",
      "✓ Feature importance saved to 'feature_importance.csv'\n",
      "\n",
      "============================================================\n",
      "✅ SHAP ANALYSIS COMPLETE - NO CRASH!\n",
      "============================================================\n",
      "\n",
      "Generated files:\n",
      "  1. shap_values.csv - Raw SHAP values\n",
      "  2. shap_sample_data.csv - Sample data used\n",
      "  3. feature_importance.csv - Feature rankings\n",
      "\n",
      "To create plots safely, run the plotting script separately.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[7/7] Saving results...\")\n",
    "shap_df = pd.DataFrame(shap_values, columns=X_sample.columns)\n",
    "shap_df.to_csv(\"shap_values.csv\", index=False)\n",
    "print(\"✓ SHAP values saved to 'shap_values.csv'\")\n",
    "\n",
    "X_sample.to_csv(\"shap_sample_data.csv\", index=False)\n",
    "print(\"✓ Sample data saved to 'shap_sample_data.csv'\")\n",
    "\n",
    "feature_importance.to_csv(\"feature_importance.csv\", index=False)\n",
    "print(\"✓ Feature importance saved to 'feature_importance.csv'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✅ SHAP ANALYSIS COMPLETE - NO CRASH!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nGenerated files:\")\n",
    "print(\"  1. shap_values.csv - Raw SHAP values\")\n",
    "print(\"  2. shap_sample_data.csv - Sample data used\")\n",
    "print(\"  3. feature_importance.csv - Feature rankings\")\n",
    "print(\"\\nTo create plots safely, run the plotting script separately.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
