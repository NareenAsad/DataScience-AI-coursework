{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59b739c4",
   "metadata": {},
   "source": [
    "# **Week 10 – Advanced Deep Learning**\n",
    "\n",
    "This week covers Convolutional Neural Networks (CNNs) for images and Recurrent Neural Networks (RNNs) for text/time-series.\n",
    "\n",
    "Since your main house price dataset is tabular, CNN/RNN cannot be directly applied to it — so the Class Task uses sample datasets, and Assignment 10 includes two paths:\n",
    "\n",
    "- If your project dataset fits CNN/RNN → apply it\n",
    "\n",
    "- If not → use a small sample dataset for demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1926b1d4",
   "metadata": {},
   "source": [
    "# **Class Task** \n",
    "\n",
    "Task 1 – Build a CNN for Image Classification\n",
    "\n",
    "- We will use the MNIST or Fashion-MNIST dataset (built-in in TensorFlow)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d69d064",
   "metadata": {},
   "source": [
    "**Step 1: Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ead8642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a62ee88",
   "metadata": {},
   "source": [
    "**Step 2: Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c5923b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 731c5ac602752760c8e48fbffcf8c3b850d9dc2a2aedcf2cc48468fc17b673d1 so we will re-download the data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize & reshape\n",
    "X_train = X_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "X_test = X_test.reshape(-1, 28, 28, 1) / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c67edf5",
   "metadata": {},
   "source": [
    "**Step 3: Build CNN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32356558",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\naree\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe78041",
   "metadata": {},
   "source": [
    "**Step 4: Compile**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0911f064",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb78bb8e",
   "metadata": {},
   "source": [
    "**Step 5: Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f741acf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - accuracy: 0.9535 - loss: 0.1576 - val_accuracy: 0.9829 - val_loss: 0.0588\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 19ms/step - accuracy: 0.9842 - loss: 0.0520 - val_accuracy: 0.9859 - val_loss: 0.0492\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 17ms/step - accuracy: 0.9883 - loss: 0.0367 - val_accuracy: 0.9881 - val_loss: 0.0417\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - accuracy: 0.9916 - loss: 0.0261 - val_accuracy: 0.9865 - val_loss: 0.0485\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - accuracy: 0.9932 - loss: 0.0208 - val_accuracy: 0.9847 - val_loss: 0.0526\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f2cbd5",
   "metadata": {},
   "source": [
    "**Step 6: Evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73cd70cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9859 - loss: 0.0447\n",
      "CNN Test Accuracy: 0.9858999848365784\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"CNN Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5fc5ed",
   "metadata": {},
   "source": [
    "Task 2 – Build an RNN for Text or Time-Series\n",
    "\n",
    "- We will use a sample IMDB Sentiment Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2457aa16",
   "metadata": {},
   "source": [
    "**Step 1: Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bfa8c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "vocab_size = 10000\n",
    "maxlen = 200\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8692e42",
   "metadata": {},
   "source": [
    "**Step 2: Build RNN (LSTM)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e979243b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Embedding(vocab_size, 128),\n",
    "    layers.LSTM(64),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3a7809",
   "metadata": {},
   "source": [
    "**Step 3: Compile & Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2c94890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 229ms/step - accuracy: 0.7894 - loss: 0.4427 - val_accuracy: 0.8400 - val_loss: 0.3637\n",
      "Epoch 2/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 299ms/step - accuracy: 0.8999 - loss: 0.2553 - val_accuracy: 0.8714 - val_loss: 0.3045\n",
      "Epoch 3/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 249ms/step - accuracy: 0.9316 - loss: 0.1856 - val_accuracy: 0.8610 - val_loss: 0.3558\n",
      "Epoch 4/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 217ms/step - accuracy: 0.9477 - loss: 0.1409 - val_accuracy: 0.8640 - val_loss: 0.3818\n",
      "Epoch 5/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 247ms/step - accuracy: 0.9657 - loss: 0.0978 - val_accuracy: 0.8342 - val_loss: 0.4285\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=64,\n",
    "                    validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d4603c",
   "metadata": {},
   "source": [
    "**Step 4: Evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f20b1252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 47ms/step - accuracy: 0.8304 - loss: 0.4446\n",
      "RNN Test Accuracy: 0.8303599953651428\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"RNN Test Accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ba0748",
   "metadata": {},
   "source": [
    "# **Assignment 10 – CNN/RNN Applicability to Project Dataset**\n",
    "\n",
    "**1. Dataset Type**\n",
    "\n",
    "My project dataset (House Price Prediction) is tabular, containing numeric and categorical features such as:\n",
    "\n",
    "- GrLivArea\n",
    "\n",
    "- OverallQual\n",
    "\n",
    "- GarageCars\n",
    "\n",
    "- SalePrice (target)\n",
    "\n",
    "This dataset is not image-based and not sequential, therefore:\n",
    "\n",
    "- CNNs cannot be applied (no spatial pixel patterns).\n",
    "\n",
    "- RNNs cannot be applied (no sequence/time dependency).\n",
    "\n",
    "**2. Reflection on Class Task**\n",
    "\n",
    "During the class task, I implemented both a Convolutional Neural Network (CNN) for image classification and a Recurrent Neural Network (RNN/LSTM) for sequence modelling. Although these models do not apply to my tabular house-price dataset, completing the class exercises helped me develop a deeper understanding of how advanced deep learning architectures work.\n",
    "\n",
    "**CNN Reflection – Image Classification**\n",
    "\n",
    "For the CNN task, I used an image dataset (such as MNIST or CIFAR-10). Through this task, I learned how CNNs automatically extract spatial features from images using:\n",
    "\n",
    "- **Convolution layers**, which detect edges, patterns, and shapes.\n",
    "\n",
    "- **Filters/kernels**, which slide across the image to learn low- and high-level features.\n",
    "\n",
    "- **Activation maps**, which represent progressively richer visual information.\n",
    "\n",
    "- **MaxPooling layers**, which help reduce dimensionality and focus on the most important features.\n",
    "\n",
    "- **Flattening + Dense layers**, which convert extracted features into classification decisions.\n",
    "\n",
    "This hands-on experience showed me **why CNNs are powerful:** they can learn important image features automatically instead of relying on manual feature engineering. It also highlighted why CNNs only make sense for **image-based or spatial data**, not tabular features.\n",
    "\n",
    "**RNN Reflection – Sequence/Text Modelling**\n",
    "\n",
    "For the RNN task, I built a model using LSTM (Long Short-Term Memory units) for text or sequence data. Through this task, I learned:\n",
    "\n",
    "- How tokenization and embeddings convert words into numeric vectors.\n",
    "\n",
    "- How recurrent networks process input one step at a time, remembering previous context.\n",
    "\n",
    "- Why LSTMs can capture long-term dependencies, making them ideal for language and time-series data.\n",
    "\n",
    "- How the model updates its hidden state as it reads each word or time step.\n",
    "\n",
    "This exercise helped me understand how RNNs learn meaningful patterns such as sentiment, trends, and sequential relationships. It also clarified why RNNs cannot be applied to my house price project: there is no sequence or time order in the features.\n",
    "\n",
    "**3. Why CNN/RNN Do NOT Fit My Project**\n",
    "\n",
    "My house price dataset:\n",
    "\n",
    "- Has no images → CNN not suitable\n",
    "\n",
    "- Has no sequence or time dimension → RNN not suitable\n",
    "\n",
    "- Features are independent columns (area, quality, rooms, etc.)\n",
    "\n",
    "- Predicting price does not require spatial filters or sequence memory\n",
    "\n",
    "**Correct Model Type for Tabular Data: ANN (Week 9)**\n",
    "\n",
    "Fully connected neural networks are the best deep learning choice for this dataset.\n",
    "\n",
    "**4. Final Conclusion**\n",
    "\n",
    "Although CNNs and RNNs were successfully implemented in the Class Task, they cannot be used for my project dataset due to the data structure.\n",
    "\n",
    "For tabular data:\n",
    "\n",
    "- ANN performs the best.\n",
    "\n",
    "- CNN has no meaningful pixel patterns to learn.\n",
    "\n",
    "- RNN has no sequences to process.\n",
    "\n",
    "Therefore, the most appropriate deep learning approach for my House Price Prediction project remains the ANN model from Week 9."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
